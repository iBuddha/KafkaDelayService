# consumer有时候会卡在(无法退出方法)获取元数据操作上，造成poll()方法无法结束，从使得一个消息的处理无法退出。所以
# consumer需要使用专门的dispatcher，以减少出现上述情况时，饿死其它actor的可能性
consumer-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  # maybe PinnedDispatcher? that is one thread for each consumer
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  thread-pool-executor {
    # minimum number of threads to cap factor-based core number to
    core-pool-size-min = 3
    # No of core threads ... ceil(available processors * factor)
    core-pool-size-factor = 2.0
    # maximum number of threads to cap factor-based number to
    core-pool-size-max = 16
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 10
}

topic-listener-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  # maybe PinnedDispatcher? that is one thread for each consumer
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  thread-pool-executor {
    # minimum number of threads to cap factor-based core number to
    core-pool-size-min = 1
    # No of core threads ... ceil(available processors * factor)
    core-pool-size-factor = 1.0
    # maximum number of threads to cap factor-based number to
    core-pool-size-max = 1
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 10
}

timer-consumer-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  # maybe PinnedDispatcher? that is one thread for each consumer
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  thread-pool-executor {
    # minimum number of threads to cap factor-based core number to
    core-pool-size-min = 3
    # No of core threads ... ceil(available processors * factor)
    core-pool-size-factor = 1.0
    # maximum number of threads to cap factor-based number to
    core-pool-size-max = 10
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 10
}

# 需要优先保证producer能正常工作，以避免由于consumer的问题导致无法发送超时的消息
producer-dispatcher {
  # Dispatcher is the name of the event-based dispatcher
  type = Dispatcher
  # What kind of ExecutionService to use
  executor = "fork-join-executor"
  # Configuration for the fork join pool
  thread-pool-executor {
    # minimum number of threads to cap factor-based core number to
    core-pool-size-min = 2
    # No of core threads ... ceil(available processors * factor)
    core-pool-size-factor = 2.0
    # maximum number of threads to cap factor-based number to
    core-pool-size-max = 4
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 100
}

kafka {
  delay-service {
    #initial-topics = ["BaseTopicA", "BaseTopicB"]
    #https://github.com/typesafehub/config/blob/master/HOCON.md#duration-format
    new-topic-check-interval = "1m"
    bootstrap-servers = "localhost:9092"
    failover {
      ignore-expire-ago = "7days"
    }
    timer{
      check-enable = true
      check-max-diff-ms = 3000
    }
    batch {
      maxSize = 1000
      maxDistance = 500
      batchTimeMs = 500
      maxRange = 5000
      dynamic {
        enable = true
        maxSize = 10000
        maxDiffMs = 2000
      }
    }
  }
}

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  actor {
    debug {
      # enable function of LoggingReceive, which is to log any received message at
      #       # DEBUG level
      receive = on
      lifecycle = on
    }
  }
}